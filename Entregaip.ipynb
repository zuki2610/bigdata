{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjMwjv7PO4/SkbV4+d34F6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuki2610/bigdata/blob/main/Entregaip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3-93__bICMW",
        "outputId": "f8891d37-3f83-4727-8980-ae5ee46882b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Instalar PySpark en el entorno de Google Colab\n",
        "!pip install pyspark\n",
        "\n",
        "# Importar PySpark y otras librerías necesarias\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, max, min, countDistinct\n",
        "\n",
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ruta a los archivos en la carpeta \"Datos\" de tu Google Drive\n",
        "ruta_segmentacion = \"/content/drive/My Drive/Datos/Segmentacion.csv\"\n",
        "ruta_precios = \"/content/drive/My Drive/Datos/Precios.csv\"\n",
        "\n",
        "# Crear una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"PySpark Example\").getOrCreate()\n",
        "\n",
        "# Cargar los archivos CSV en DataFrames de PySpark\n",
        "segmentacion_df = spark.read.csv(ruta_segmentacion, header=True, inferSchema=True)\n",
        "precios_df = spark.read.csv(ruta_precios, header=True, inferSchema=True)\n",
        "\n",
        "# Mostrar una vista previa de los datos\n",
        "print(\"Vista previa de la segmentación:\")\n",
        "segmentacion_df.show(5)\n",
        "print(\"Vista previa de los precios:\")\n",
        "precios_df.show(5)\n",
        "\n",
        "# *1. Validar cuántos registros tienen ambos archivos*\n",
        "segmentacion_count = segmentacion_df.count()\n",
        "precios_count = precios_df.count()\n",
        "\n",
        "print(f\"Registros en segmentación: {segmentacion_count}\")\n",
        "print(f\"Registros en precios: {precios_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84j9k-SxJdhH",
        "outputId": "572558be-5508-4f80-e7db-9c7c64a34406"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vista previa de la segmentación:\n",
            "+--------+--------+\n",
            "| RUT_CLI|SEGMENTO|\n",
            "+--------+--------+\n",
            "|96635170|       1|\n",
            "|76256513|       1|\n",
            "|77108943|       1|\n",
            "|92975000|       1|\n",
            "|89201400|       1|\n",
            "+--------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Vista previa de los precios:\n",
            "+-----+---+------+------------------+\n",
            "|GROUP|FAM|SUBFAM|             VALUE|\n",
            "+-----+---+------+------------------+\n",
            "|    0|  1|     1|0.2350543478260869|\n",
            "|    0|  1|     1| 0.198444661032879|\n",
            "|    0|  1|     1|0.2919982088695311|\n",
            "|    0|  1|     1|0.2272116796417313|\n",
            "|    0|  1|     1|0.2518425219231205|\n",
            "+-----+---+------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Registros en segmentación: 126104\n",
            "Registros en precios: 11018159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# *2. Realizar una partición de la matriz precio por familia-subfamilia*\n",
        "precios_partitioned = precios_df.repartition(\"fam\", \"subfam\")\n",
        "print(\"Matriz de precios particionada por familia y subfamilia.\")\n",
        "print(precios_partitioned.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBYWJHhOJdrO",
        "outputId": "332f63d7-77ee-4bb4-90d6-063c962073fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de precios particionada por familia y subfamilia.\n",
            "+-----+---+------+------------------+\n",
            "|GROUP|FAM|SUBFAM|             VALUE|\n",
            "+-----+---+------+------------------+\n",
            "|    0| 10|     2|0.3857003916848538|\n",
            "|    0| 10|     2|0.3677940968114483|\n",
            "|    0| 10|     2|0.3901394142121732|\n",
            "|    0| 10|     2|0.3030408779958913|\n",
            "|    0| 10|     2|0.3586941963298005|\n",
            "|    0| 10|     2|0.3612035640135574|\n",
            "|    0| 10|     2|0.3106493323990148|\n",
            "|    0| 10|     2|0.1715160796324655|\n",
            "|    0| 10|     2|0.3618363058629711|\n",
            "|    0| 10|     2|0.1961770267341639|\n",
            "|    0| 10|     2|0.4078984485190409|\n",
            "|    0| 10|     2|0.3257364115216078|\n",
            "|    0| 10|     2|0.3437300811423489|\n",
            "|    0| 10|     2|0.3431603096604355|\n",
            "|    0| 10|     2|0.2839106891413789|\n",
            "|    0| 10|     2|0.3891248934304149|\n",
            "|    0| 10|     2|0.3099415204678363|\n",
            "|    0| 10|     2|0.3975318912922906|\n",
            "|    0| 10|     2|0.3833524561218172|\n",
            "|    0| 10|     2|0.3093344534992925|\n",
            "+-----+---+------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Validar que los valores (márgenes) estén entre 0.1 y 1\n",
        "valid_margins = precios_df.filter((col(\"value\") >= 0.1) & (col(\"value\") <= 1))\n",
        "\n",
        "# Contar cuántos registros tienen márgenes válidos\n",
        "valid_margins_count = valid_margins.count()\n",
        "\n",
        "# Contar el total de registros\n",
        "total_count = precios_df.count()\n",
        "\n",
        "print(f\"Registros con márgenes válidos (0.1 a 1): {valid_margins_count}\")\n",
        "print(f\"Total de registros en el DataFrame: {total_count}\")\n",
        "print(f\"Porcentaje de márgenes válidos: {100 * valid_margins_count / total_count:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt2RuUFBOmZ1",
        "outputId": "2d13499e-e2e2-4859-8fac-41a871c7a4ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registros con márgenes válidos (0.1 a 1): 11018159\n",
            "Total de registros en el DataFrame: 11018159\n",
            "Porcentaje de márgenes válidos: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, countDistinct, avg\n",
        "\n",
        "'''\n",
        "# Cargar los archivos CSV en DataFrames de PySpark\n",
        "segmentacion_df = spark.read.csv(ruta_segmentacion, header=True, inferSchema=True)\n",
        "precios_df = spark.read.csv(ruta_precios, header=True, inferSchema=True)\n",
        "\n",
        "# Mostrar una vista previa de los datos\n",
        "print(\"Vista previa de la segmentación:\")\n",
        "segmentacion_df.show(5)\n",
        "print(\"Vista previa de los precios:\")\n",
        "precios_df.show(5)\n",
        "'''\n",
        "# Realizar la unión entre los DataFrames en GROUP y SEGMENTO\n",
        "segmentacion_precios_df = precios_df.join(\n",
        "    segmentacion_df,\n",
        "    segmentacion_df[\"SEGMENTO\"] == precios_df[\"GROUP\"],\n",
        "    \"inner\"\n",
        ")\n",
        "\n",
        "# Contar clientes únicos (RUT_CLI) por grupo (GROUP)\n",
        "clientes_por_grupo = segmentacion_precios_df.groupBy(\"GROUP\").agg(\n",
        "    countDistinct(\"RUT_CLI\").alias(\"clientes_unicos\")\n",
        ")\n",
        "\n",
        "# Calcular el promedio de clientes únicos por grupo\n",
        "promedio_clientes_por_grupo = clientes_por_grupo.agg(\n",
        "    avg(\"clientes_unicos\").alias(\"promedio_clientes\")\n",
        ").collect()[0][\"promedio_clientes\"]\n",
        "\n",
        "print(f\"Promedio de clientes únicos por grupo: {promedio_clientes_por_grupo}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssaPx4MdK5FK",
        "outputId": "2ca8c7fb-5e5a-46fd-f976-d012d245ba71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de clientes únicos por grupo: 26.910798122065728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, max, avg, min\n",
        "\n",
        "# Realizar la unión entre los DataFrames en SEGMENTO y GROUP\n",
        "segmentacion_precios_df = segmentacion_df.join(\n",
        "    precios_df,\n",
        "    segmentacion_df[\"SEGMENTO\"] == precios_df[\"GROUP\"],\n",
        "    \"inner\"\n",
        ")\n",
        "\n",
        "# Filtrar los registros para el RUT_CLI = 66666666\n",
        "rut_66666666_df = segmentacion_precios_df.filter(col(\"RUT_CLI\") == 66666666)\n",
        "\n",
        "# Calcular márgenes (valores) máximos, promedios y mínimos\n",
        "margen_estadisticas = rut_66666666_df.agg(\n",
        "    max(\"VALUE\").alias(\"margen_maximo\"),\n",
        "    avg(\"VALUE\").alias(\"margen_promedio\"),\n",
        "    min(\"VALUE\").alias(\"margen_minimo\")\n",
        ").collect()\n",
        "\n",
        "# Extraer los resultados\n",
        "margen_maximo = margen_estadisticas[0][\"margen_maximo\"]\n",
        "margen_promedio = margen_estadisticas[0][\"margen_promedio\"]\n",
        "margen_minimo = margen_estadisticas[0][\"margen_minimo\"]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Márgenes para el RUT_CLI 66666666:\")\n",
        "print(f\"Máximo: {margen_maximo}\")\n",
        "print(f\"Promedio: {margen_promedio}\")\n",
        "print(f\"Mínimo: {margen_minimo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZCl6nOQX2Wt",
        "outputId": "3250495b-7dd6-4078-e323-44dab1e64234"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Márgenes para el RUT_CLI 66666666:\n",
            "Máximo: 0.7415512051396618\n",
            "Promedio: 0.39309233080261313\n",
            "Mínimo: 0.2106912324480014\n"
          ]
        }
      ]
    }
  ]
}